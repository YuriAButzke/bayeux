{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LGXFk0LJQzq4"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import dynamax\n",
        "except ModuleNotFoundError:\n",
        "    print('installing dynamax')\n",
        "    %pip install -qq dynamax\n",
        "    import dynamax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "executionInfo": {
          "elapsed": 80317,
          "status": "ok",
          "timestamp": 1704904855441,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 300
        },
        "id": "XMTEI6ep4D_S"
      },
      "outputs": [],
      "source": [
        "import bayeux as bx\n",
        "import jax\n",
        "from itertools import count\n",
        "\n",
        "from dynamax.linear_gaussian_ssm import LinearGaussianSSM\n",
        "from dynamax.parameters import log_det_jac_constrain\n",
        "from dynamax.parameters import to_unconstrained, from_unconstrained\n",
        "from dynamax.utils.utils import ensure_array_has_batch_dim\n",
        "from functools import partial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4wciun69_Pn"
      },
      "source": [
        "# Using bayeux with Dynamax\n",
        "\n",
        "[`dynamax`](https://probml.github.io/dynamax/) is a library for probabilistic state space models written in JAX. `dynamax` builds a pure JAX likelihood function from a model, and hence is compatible with other libraries in the JAX ecosystem: we can estimate model parameters using other JAX libraries such as `optax` (via stochastic gradient descent) and `blackjax` (via sampling).\n",
        "\n",
        "Here, we will provide minimal steps to recreate the inference stage for an example from the `dynamax` documentation for [Bayesian parameter estimation for a linear Gaussian state space model using HMC](https://probml.github.io/dynamax/notebooks/linear_gaussian_ssm/lgssm_hmc.html). Writing inference loops in `blackjax`, especially for [multiple chains](https://blackjax-devs.github.io/blackjax/examples/howto_sample_multiple_chains.html), can be quite cumbersome. We will use `bayeux` to reduce some of the boilerplate code.\n",
        "\n",
        "This example shows how we can take any model in a JAX library and use `bayeux` to perform inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "executionInfo": {
          "elapsed": 2063,
          "status": "ok",
          "timestamp": 1704904857538,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 300
        },
        "id": "EiEtvl1zokAG"
      },
      "outputs": [],
      "source": [
        "state_dim = 2\n",
        "emission_dim = 10\n",
        "num_timesteps = 100\n",
        "keys = map(jax.random.PRNGKey, count())\n",
        "\n",
        "# simulate synthetic data from true model\n",
        "true_model = LinearGaussianSSM(state_dim, emission_dim)\n",
        "true_params, _ = true_model.initialize(next(keys))\n",
        "true_states, emissions = true_model.sample(true_params, next(keys), num_timesteps)\n",
        "\n",
        "test_model = LinearGaussianSSM(state_dim, emission_dim)\n",
        "initial_params, param_props = test_model.initialize(next(keys))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dynamax_logdensity(\n",
        "        model,\n",
        "        props,\n",
        "        emissions,\n",
        "        inputs=None,\n",
        "    ):\n",
        "    \"\"\"Convert dynamax model into log-desnity function.\"\"\"\n",
        "    # Make sure the emissions and inputs have batch dimensions\n",
        "    batch_emissions = ensure_array_has_batch_dim(emissions, model.emission_shape)\n",
        "    batch_inputs = ensure_array_has_batch_dim(inputs, model.inputs_shape)\n",
        "\n",
        "    # log likelihood that the HMC samples from\n",
        "    def _logprob(unc_params):\n",
        "        params = from_unconstrained(unc_params, props)\n",
        "        batch_lls = jax.vmap(partial(model.marginal_log_prob, params))(batch_emissions, batch_inputs)\n",
        "        lp = model.log_prior(params) + batch_lls.sum()\n",
        "        lp += log_det_jac_constrain(params, props)\n",
        "        return lp\n",
        "\n",
        "    return _logprob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "log_density = dynamax_logdensity(test_model, param_props, emissions)\n",
        "initial_unc_params = to_unconstrained(initial_params, param_props)\n",
        "\n",
        "ssm_density = bx.Model(\n",
        "  log_density=log_density,\n",
        "  test_point=initial_unc_params\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can use `debug` mode to help check if the model is correctly implemented."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking test_point shape ✓ \n",
            "Computing test point log density ✓ \n",
            "Loading keyword arguments... ✓ \n",
            "Checking it is possible to compute an initial state ✓ \n",
            "Checking initial state is has no NaN ✓ \n",
            "Computing initial state log density ✓ \n",
            "Transforming model to R^n ✓ \n",
            "Computing transformed state log density shape ✓ \n",
            "Computing gradients of transformed log density ✓ \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seed = jax.random.PRNGKey(0)\n",
        "\n",
        "ssm_density.mcmc.blackjax_hmc.debug(seed=seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see which arguments we can modify before they are passed on to the `blackjax` algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{<function blackjax.adaptation.window_adaptation.window_adaptation(algorithm: Union[blackjax.mcmc.hmc.hmc, blackjax.mcmc.nuts.nuts], logdensity_fn: Callable, is_mass_matrix_diagonal: bool = True, initial_step_size: float = 1.0, target_acceptance_rate: float = 0.8, progress_bar: bool = False, **extra_parameters) -> blackjax.base.AdaptationAlgorithm>: {'num_integration_steps': 16,\n",
              "  'logdensity_fn': <function bayeux._src.shared.constrain.<locals>.wrap_log_density.<locals>.wrapped(args)>,\n",
              "  'is_mass_matrix_diagonal': True,\n",
              "  'initial_step_size': 1.0,\n",
              "  'target_acceptance_rate': 0.8,\n",
              "  'progress_bar': False,\n",
              "  'algorithm': blackjax.mcmc.hmc.hmc},\n",
              " 'adapt.run': {'num_steps': 500},\n",
              " blackjax.mcmc.hmc.hmc: {'divergence_threshold': 1000,\n",
              "  'integrator': <function blackjax.mcmc.integrators.generate_euclidean_integrator.<locals>.euclidean_integrator(logdensity_fn: Callable, kinetic_energy_fn: blackjax.mcmc.metrics.KineticEnergy) -> Callable[[blackjax.mcmc.integrators.IntegratorState, float], blackjax.mcmc.integrators.IntegratorState]>,\n",
              "  'step_size': 0.5,\n",
              "  'num_integration_steps': 16,\n",
              "  'logdensity_fn': <function bayeux._src.shared.constrain.<locals>.wrap_log_density.<locals>.wrapped(args)>},\n",
              " 'extra_parameters': {'chain_method': 'vectorized',\n",
              "  'num_chains': 8,\n",
              "  'num_draws': 500,\n",
              "  'num_adapt_draws': 500,\n",
              "  'return_pytree': False}}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ssm_density.mcmc.blackjax_hmc.get_kwargs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running window adaptation\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='500' class='' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [500/500 00:00&lt;?]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "samples = ssm_density.mcmc.blackjax_hmc(\n",
        "    seed=seed,\n",
        "    chain_method=\"vectorized\",\n",
        "    num_chains=2,\n",
        "    num_draws=500,\n",
        "    num_integration_steps=30,\n",
        "    progress_bar=True,\n",
        "    return_pytree=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are not just limited to `blackjax`, we can use another sampling backend like `numpyro`, or we can use gradient descent and other options, all with a simple interface thanks to `bayeux`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mcmc\n",
            "\t.tfp_hmc\n",
            "\t.tfp_nuts\n",
            "\t.tfp_snaper_hmc\n",
            "\t.blackjax_hmc\n",
            "\t.blackjax_chees_hmc\n",
            "\t.blackjax_meads_hmc\n",
            "\t.blackjax_nuts\n",
            "\t.blackjax_hmc_pathfinder\n",
            "\t.blackjax_nuts_pathfinder\n",
            "\t.flowmc_rqspline_hmc\n",
            "\t.flowmc_rqspline_mala\n",
            "\t.flowmc_realnvp_hmc\n",
            "\t.flowmc_realnvp_mala\n",
            "\t.numpyro_hmc\n",
            "\t.numpyro_nuts\n",
            "optimize\n",
            "\t.jaxopt_bfgs\n",
            "\t.jaxopt_gradient_descent\n",
            "\t.jaxopt_lbfgs\n",
            "\t.jaxopt_nonlinear_cg\n",
            "\t.optimistix_bfgs\n",
            "\t.optimistix_chord\n",
            "\t.optimistix_dogleg\n",
            "\t.optimistix_gauss_newton\n",
            "\t.optimistix_indirect_levenberg_marquardt\n",
            "\t.optimistix_levenberg_marquardt\n",
            "\t.optimistix_nelder_mead\n",
            "\t.optimistix_newton\n",
            "\t.optimistix_nonlinear_cg\n",
            "\t.optax_adabelief\n",
            "\t.optax_adafactor\n",
            "\t.optax_adagrad\n",
            "\t.optax_adam\n",
            "\t.optax_adamw\n",
            "\t.optax_adamax\n",
            "\t.optax_amsgrad\n",
            "\t.optax_fromage\n",
            "\t.optax_lamb\n",
            "\t.optax_lion\n",
            "\t.optax_noisy_sgd\n",
            "\t.optax_novograd\n",
            "\t.optax_radam\n",
            "\t.optax_rmsprop\n",
            "\t.optax_sgd\n",
            "\t.optax_sm3\n",
            "\t.optax_yogi\n",
            "vi\n",
            "\t.tfp_factored_surrogate_posterior\n"
          ]
        }
      ],
      "source": [
        "print(ssm_density)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "provenance": [],
      "toc_visible": true
    },
    "jupytext": {
      "formats": "ipynb,md:myst"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
